{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "\n",
    "API reference: https://www.zillow.com/research/data/\n",
    "Data located in data/csv folder\n",
    "Data file path mapped to HOME_VALUES dictionary\n",
    "\n",
    "'''\n",
    "\n",
    "METRO_AND_US_HOME_VALUES = {\n",
    "    'ZHVI All Homes (SFR, Condo/Co-op) Time Series, Smoothed, Seasonally Adjusted ($)': './data/csv/metro_and_us/Metro_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI All Homes (SFR, Condo/Co-op) Time Series, Raw, Mid-Tier ($)': './data/csv/metro_and_us/Metro_zhvi_uc_sfrcondo_tier_0.33_0.67_month.csv',\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/metro_and_us/Metro_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 2-Bedroom Time Series ($)': './data/csv/metro_and_us/Metro_zhvi_bdrmcnt_2_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 3-Bedroom Time Series ($)': './data/csv/metro_and_us/Metro_zhvi_bdrmcnt_3_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 4-Bedroom Time Series ($)': './data/csv/metro_and_us/Metro_zhvi_bdrmcnt_4_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 5-Bedroom Time Series ($)': './data/csv/metro_and_us/Metro_zhvi_bdrmcnt_5_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "CITY_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "STATE_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/state/State_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "ZIP_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/zip/Zip_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "COUNTY_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/county/County_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "NEIGHBORHOOD_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/neighborhood/Neighborhood_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "one_bedroom_homes = METRO_AND_US_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "two_bedroom_homes = METRO_AND_US_HOME_VALUES[\"ZHVI 2-Bedroom Time Series ($)\"]\n",
    "three_bedroom_homes = METRO_AND_US_HOME_VALUES[\"ZHVI 3-Bedroom Time Series ($)\"]\n",
    "four_bedroom_homes = METRO_AND_US_HOME_VALUES[\"ZHVI 4-Bedroom Time Series ($)\"]\n",
    "five_bedroom_homes = METRO_AND_US_HOME_VALUES[\"ZHVI 5-Bedroom Time Series ($)\"]\n",
    "\n",
    "city_one_bedroom_homes = CITY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "state_one_bedroom_homes = STATE_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "zip_one_bedroom_homes = ZIP_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "county_one_bedroom_homes = COUNTY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "neighborhood_one_bedroom_homes = NEIGHBORHOOD_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "def load_csv(filename: str) -> list:\n",
    "    with open(filename, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        # next(reader)\n",
    "        data = list(reader)\n",
    "        return data\n",
    "\n",
    "def main():\n",
    "    # data = load_csv(csv_file)\n",
    "    # print(json.dumps(data, indent=4))\n",
    "    print(\"=\" * 90)\n",
    "    print(\"Metro and US Data\\n\")\n",
    "    df = pd.read_csv(one_bedroom_homes)    \n",
    "    # print(df.head())\n",
    "    # print(df.tail())  \n",
    "    # print(df.describe())    \n",
    "    print(df.sample(20)) \n",
    "    \n",
    "    print(\"=\" * 90)    \n",
    "    print(\"City Data\\n\")\n",
    "    df = pd.read_csv(city_one_bedroom_homes)    \n",
    "    # print(df.head())\n",
    "    # print(df.tail())  \n",
    "    # print(df.describe())    \n",
    "    print(df.sample(20))\n",
    "    print(df[df[\"RegionName\"] == \"San Diego\"])\n",
    "    print(df[df[\"RegionName\"] == \"Los Angeles\"])\n",
    "    \n",
    "    print(\"=\" * 90) \n",
    "    print(\"State Data\\n\")\n",
    "    df = pd.read_csv(state_one_bedroom_homes)    \n",
    "    # print(df.head())\n",
    "    # print(df.tail())  \n",
    "    # print(df.describe())    \n",
    "    print(df.sample(20)) \n",
    "    print(df[df[\"RegionName\"] == \"California\"])\n",
    "    print(df[df[\"RegionName\"] == \"Texas\"])\n",
    "    \n",
    "    print(\"=\" * 90) \n",
    "    print(\"Zip Code Data\\n\")\n",
    "    df = pd.read_csv(zip_one_bedroom_homes)    \n",
    "    # print(df.head())\n",
    "    # print(df.tail())  \n",
    "    # print(df.describe())    \n",
    "    print(df.sample(20)) \n",
    "    print(df[df[\"RegionName\"] == 92103])\n",
    "    print(df[df[\"RegionName\"] == 92109])\n",
    "    \n",
    "    print(\"=\" * 90) \n",
    "    print(\"County Data\\n\")\n",
    "    df = pd.read_csv(county_one_bedroom_homes)    \n",
    "    # print(df.head())\n",
    "    # print(df.tail())  \n",
    "    # print(df.describe())    \n",
    "    print(df.sample(20)) \n",
    "    print(df[df[\"RegionName\"] == \"San Diego County\"])\n",
    "    print(df[df[\"RegionName\"] == \"Humboldt County\"])\n",
    "    \n",
    "    print(\"=\" * 90) \n",
    "    print(\"Neighborhood Data\\n\")\n",
    "    df = pd.read_csv(neighborhood_one_bedroom_homes)    \n",
    "    # print(df.head())\n",
    "    # print(df.tail())  \n",
    "    # print(df.describe())    \n",
    "    print(df.sample(20)) \n",
    "    print(df[df[\"RegionName\"] == \"Linda Vista\"])\n",
    "    print(df[df[\"RegionName\"] == \"Hollywood\"])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, warnings\n",
    "import sklearn.cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "\n",
    "API reference: https://www.zillow.com/research/data/\n",
    "Data located in data/csv folder\n",
    "Data file path mapped to HOME_VALUES dictionary\n",
    "\n",
    "'''\n",
    "\n",
    "METRO_AND_US_HOME_VALUES = {\n",
    "    'ZHVI All Homes (SFR, Condo/Co-op) Time Series, Smoothed, Seasonally Adjusted ($)': './data/csv/metro_and_us/Metro_zhvi_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI All Homes (SFR, Condo/Co-op) Time Series, Raw, Mid-Tier ($)': './data/csv/metro_and_us/Metro_zhvi_uc_sfrcondo_tier_0.33_0.67_month.csv',\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/metro_and_us/Metro_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 2-Bedroom Time Series ($)': './data/csv/metro_and_us/Metro_zhvi_bdrmcnt_2_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 3-Bedroom Time Series ($)': './data/csv/metro_and_us/Metro_zhvi_bdrmcnt_3_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 4-Bedroom Time Series ($)': './data/csv/metro_and_us/Metro_zhvi_bdrmcnt_4_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 5-Bedroom Time Series ($)': './data/csv/metro_and_us/Metro_zhvi_bdrmcnt_5_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "CITY_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "STATE_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/state/State_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "ZIP_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/zip/Zip_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "COUNTY_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/county/County_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "NEIGHBORHOOD_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/neighborhood/Neighborhood_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "one_bedroom_homes = METRO_AND_US_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "two_bedroom_homes = METRO_AND_US_HOME_VALUES[\"ZHVI 2-Bedroom Time Series ($)\"]\n",
    "three_bedroom_homes = METRO_AND_US_HOME_VALUES[\"ZHVI 3-Bedroom Time Series ($)\"]\n",
    "four_bedroom_homes = METRO_AND_US_HOME_VALUES[\"ZHVI 4-Bedroom Time Series ($)\"]\n",
    "five_bedroom_homes = METRO_AND_US_HOME_VALUES[\"ZHVI 5-Bedroom Time Series ($)\"]\n",
    "\n",
    "city_one_bedroom_homes = CITY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "state_one_bedroom_homes = STATE_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "zip_one_bedroom_homes = ZIP_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "county_one_bedroom_homes = COUNTY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "neighborhood_one_bedroom_homes = NEIGHBORHOOD_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "def load_csv(filename: str) -> list:\n",
    "    with open(filename, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        # next(reader)\n",
    "        data = list(reader)\n",
    "        return data\n",
    "\n",
    "def main():\n",
    "    \n",
    "    affordable_home_price = 400000\n",
    "    \n",
    "    # # data = load_csv(csv_file)\n",
    "    # # print(json.dumps(data, indent=4))\n",
    "    # print(\"=\" * 90)\n",
    "    # print(\"Metro and US Data\\n\")\n",
    "    # df = pd.read_csv(one_bedroom_homes)\n",
    "    # df.dropna(inplace=True)\n",
    "    # # print(df.head())\n",
    "    # # print(df.tail())  \n",
    "    # # print(df.describe())    \n",
    "    # print(df.sample(20)) \n",
    "    \n",
    "    print(\"=\" * 90)    \n",
    "    print(\"City Data\\n\")\n",
    "    df = pd.read_csv(city_one_bedroom_homes)\n",
    "    \n",
    "    # print(df.head())\n",
    "    # print(df.columns)\n",
    "    \n",
    "    time_series_cols = df.columns[8:]\n",
    "    # print(time_series_cols)\n",
    "    # print(time_series_cols[:5]) \n",
    "    data_cleaned = df.dropna(subset=time_series_cols).reset_index(drop=True)\n",
    "    \n",
    "    data_cleaned['AvgGrowthRate'] = data_cleaned[time_series_cols].pct_change(axis=1).mean(axis=1)\n",
    "    data_cleaned['TotalGrowth'] = (data_cleaned[time_series_cols[-1]] - data_cleaned[time_series_cols[0]]) / data_cleaned[time_series_cols[0]]\n",
    "    # print(data_cleaned[['RegionName', 'State', 'AvgGrowthRate', 'TotalGrowth']].shape)  # Check the number of rows\n",
    "    # print(data_cleaned[['RegionName', 'State', 'AvgGrowthRate', 'TotalGrowth']].tail(10))  # View more rows\n",
    "    \n",
    "    # print(data_cleaned[['RegionName', 'State', 'AvgGrowthRate', 'TotalGrowth']].sort_values(by='TotalGrowth', ascending=False).head(50))\n",
    "    \n",
    "    features = ['AvgGrowthRate', 'TotalGrowth']\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(data_cleaned[features])\n",
    "    print(features_scaled)\n",
    "    # print(\"=\" * 90) \n",
    "    # data_cleaned[\"ScaledAvgGrowthRate\"] = features_scaled[:, 0]\n",
    "    # data_cleaned[\"ScaledTotalGrowth\"] = features_scaled[:, 1]\n",
    "    # print(data_cleaned[['RegionName', 'State', 'ScaledAvgGrowthRate', 'ScaledTotalGrowth']].sort_values(by='ScaledTotalGrowth', ascending=False).head(50))\n",
    "    \n",
    "    # # print(df.shape)  # Before filtering\n",
    "    # # print(data_cleaned.shape)  # After cleaning\n",
    "\n",
    "    for k in range(1, 10):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(features_scaled)\n",
    "        clusters = kmeans.predict(features_scaled)\n",
    "        data_cleaned[f'Cluster{k}'] = clusters\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(data_cleaned)\n",
    "    region_name = data_cleaned['RegionName']\n",
    "    # print(region_name)\n",
    "    \n",
    "    # # Average growth rate\n",
    "    # data_cleaned['AvgGrowthRate'] = data_cleaned[time_series_cols].pct_change(axis=1).mean(axis=1)\n",
    "    # print(data_cleaned[['RegionName', 'State', 'AvgGrowthRate']].head())\n",
    "    \n",
    "    # df.dropna(inplace=True)\n",
    "    # print(df.columns)\n",
    "\n",
    "    \n",
    "    \n",
    "    # # print(df.head())\n",
    "    # # print(df.tail())  \n",
    "    # # print(df.describe())    \n",
    "    # print(df.sample(20))\n",
    "    # print(df[df[\"RegionName\"] == \"San Diego\"])\n",
    "    # print(df[df[\"RegionName\"] == \"Los Angeles\"])\n",
    "    \n",
    "    # print(\"=\" * 90) \n",
    "    # print(\"State Data\\n\")\n",
    "    # df = pd.read_csv(state_one_bedroom_homes)    \n",
    "    # # print(df.head())\n",
    "    # # print(df.tail())  \n",
    "    # # print(df.describe())    \n",
    "    # print(df.sample(20)) \n",
    "    # print(df[df[\"RegionName\"] == \"California\"])\n",
    "    # print(df[df[\"RegionName\"] == \"Texas\"])\n",
    "    \n",
    "    # print(\"=\" * 90) \n",
    "    # print(\"Zip Code Data\\n\")\n",
    "    # df = pd.read_csv(zip_one_bedroom_homes)    \n",
    "    # # print(df.head())\n",
    "    # # print(df.tail())  \n",
    "    # # print(df.describe())    \n",
    "    # print(df.sample(20)) \n",
    "    # print(df[df[\"RegionName\"] == 92103])\n",
    "    # print(df[df[\"RegionName\"] == 92109])\n",
    "    \n",
    "    # print(\"=\" * 90) \n",
    "    # print(\"County Data\\n\")\n",
    "    # df = pd.read_csv(county_one_bedroom_homes)    \n",
    "    # # print(df.head())\n",
    "    # # print(df.tail())  \n",
    "    # # print(df.describe())    \n",
    "    # print(df.sample(20)) \n",
    "    # print(df[df[\"RegionName\"] == \"San Diego County\"])\n",
    "    # print(df[df[\"RegionName\"] == \"Humboldt County\"])\n",
    "    \n",
    "    # print(\"=\" * 90) \n",
    "    # print(\"Neighborhood Data\\n\")\n",
    "    # df = pd.read_csv(neighborhood_one_bedroom_homes)    \n",
    "    # # print(df.head())\n",
    "    # # print(df.tail())  \n",
    "    # # print(df.describe())    \n",
    "    # print(df.sample(20)) \n",
    "    # print(df[df[\"RegionName\"] == \"Linda Vista\"])\n",
    "    # print(df[df[\"RegionName\"] == \"Hollywood\"])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, warnings\n",
    "import sklearn.cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "\n",
    "API reference: https://www.zillow.com/research/data/\n",
    "Data located in data/csv folder\n",
    "Data file path mapped to HOME_VALUES dictionary\n",
    "\n",
    "'''\n",
    "\n",
    "CITY_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "city_one_bedroom_homes = CITY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "\n",
    "def load_csv(filename: str) -> list:\n",
    "    with open(filename, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        # next(reader)\n",
    "        data = list(reader)\n",
    "        return data\n",
    "\n",
    "def main():\n",
    "    \n",
    "    affordable_home_price = 400000\n",
    "    \n",
    "    # # data = load_csv(csv_file)\n",
    "    # # print(json.dumps(data, indent=4))\n",
    "    # print(\"=\" * 90)\n",
    "    # print(\"Metro and US Data\\n\")\n",
    "    # df = pd.read_csv(one_bedroom_homes)\n",
    "    # df.dropna(inplace=True)\n",
    "    # # print(df.head())\n",
    "    # # print(df.tail())  \n",
    "    # # print(df.describe())    \n",
    "    # print(df.sample(20)) \n",
    "    \n",
    "    print(\"=\" * 90)    \n",
    "    print(\"City Data\\n\")\n",
    "    df = pd.read_csv(city_one_bedroom_homes)\n",
    "    \n",
    "    # print(df.head())\n",
    "    # print(df.columns)\n",
    "    \n",
    "    time_series_cols = df.columns[8:]\n",
    "    # print(time_series_cols)\n",
    "    # print(time_series_cols[:5]) \n",
    "    data_cleaned = df.dropna(subset=time_series_cols).reset_index(drop=True)\n",
    "    \n",
    "    data_cleaned['AvgGrowthRate'] = data_cleaned[time_series_cols].pct_change(axis=1).mean(axis=1)\n",
    "    data_cleaned['TotalGrowth'] = (data_cleaned[time_series_cols[-1]] - data_cleaned[time_series_cols[0]]) / data_cleaned[time_series_cols[0]]\n",
    "    # print(data_cleaned[['RegionName', 'State', 'AvgGrowthRate', 'TotalGrowth']].shape)  # Check the number of rows\n",
    "    # print(data_cleaned[['RegionName', 'State', 'AvgGrowthRate', 'TotalGrowth']].tail(10))  # View more rows\n",
    "    \n",
    "    # print(data_cleaned[['RegionName', 'State', 'AvgGrowthRate', 'TotalGrowth']].sort_values(by='TotalGrowth', ascending=False).head(50))\n",
    "    \n",
    "    features = ['AvgGrowthRate', 'TotalGrowth']\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(data_cleaned[features])\n",
    "    # print(features_scaled)\n",
    "    # print(\"=\" * 90) \n",
    "    # data_cleaned[\"ScaledAvgGrowthRate\"] = features_scaled[:, 0]\n",
    "    # data_cleaned[\"ScaledTotalGrowth\"] = features_scaled[:, 1]\n",
    "    print(data_cleaned[['RegionName', 'State', 'ScaledAvgGrowthRate', 'ScaledTotalGrowth']].sort_values(by='ScaledTotalGrowth', ascending=False).head(50))\n",
    "    \n",
    "    # # print(df.shape)  # Before filtering\n",
    "    # # print(data_cleaned.shape)  # After cleaning\n",
    "\n",
    "    for k in range(1, 10):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(features_scaled)\n",
    "        clusters = kmeans.predict(features_scaled)\n",
    "        data_cleaned[f'Cluster{k}'] = clusters\n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, warnings\n",
    "import sklearn.cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Ensure all columns are displayed\n",
    "pd.set_option('display.width', 1000)       # Set a large enough width\n",
    "\n",
    "# Set the column width to avoid truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "'''\n",
    "\n",
    "API reference: https://www.zillow.com/research/data/\n",
    "Data located in data/csv folder\n",
    "Data file path mapped to HOME_VALUES dictionary\n",
    "\n",
    "'''\n",
    "\n",
    "CITY_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "city_one_bedroom_homes = CITY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"]\n",
    "\n",
    "\n",
    "def load_csv(filename: str) -> list:\n",
    "    with open(filename, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        # next(reader)\n",
    "        data = list(reader)\n",
    "        return data\n",
    "\n",
    "\n",
    "def build_k_means_model():\n",
    "    k_means = sklearn.cluster.KMeans(n_clusters=4)\n",
    "    # k_means.labels_\n",
    "    # k_means.cluster_centers_\n",
    "\n",
    "def test_missing_data(df):\n",
    "    # Group columns by year\n",
    "    missing_by_year = (\n",
    "        df[[col for col in df.columns if '-' in col]]  # Select only date columns\n",
    "        .isnull()\n",
    "        .mean()\n",
    "        .groupby(lambda col: col[:4])  # Group by year (first 4 characters of column name)\n",
    "        .mean()\n",
    "        * 100\n",
    "    )\n",
    "    \n",
    "    print(missing_by_year)\n",
    "    missing_by_year.plot(kind='line', figsize=(10, 6), marker='o', title=\"Missing Data Percentage by Year\")\n",
    "    plt.ylabel(\"Percentage of Missing Data\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    \n",
    "    affordable_home_price = 400000\n",
    "    \n",
    "    start_year = \"2020\"\n",
    "    \n",
    "    df = pd.read_csv(city_one_bedroom_homes)\n",
    "    # print(df.head())\n",
    "    # print(df.tail())\n",
    "    # print(df.sample(20))\n",
    "    # print(df.describe())\n",
    "    \n",
    "    # # Summary of the dataset\n",
    "    # print(df.info())\n",
    "    \n",
    "    # print columns\n",
    "    # print(df.columns)\n",
    "    \n",
    "    # # Check for missing values\n",
    "    # print(df.isnull().sum())\n",
    "    \n",
    "    # # Descriptive statistics\n",
    "    # print(df.describe())\n",
    "    \n",
    "    date_columns = [col for col in df.columns if col.startswith(\"20\") and col >= start_year]\n",
    "    \n",
    "    df[\"missing_home_values\"] = df[date_columns].isnull().sum(axis=1)\n",
    "    df_sorted = df.sort_values(by=\"missing_home_values\", ascending=False)\n",
    "    # print(df_sorted)\n",
    "    missing_summary = df_sorted[['RegionName', 'missing_home_values']]\n",
    "    # print(missing_summary)\n",
    "        \n",
    "    # filtered_columns = [\"RegionID\", \"SizeRank\", \"RegionName\", \"RegionType\", \"StateName\", \"State\", \"Metro\", \"CountyName\"] + data_columns\n",
    "    filtered_columns = [\"RegionName\", \"State\"] + date_columns\n",
    "    # print(filtered_columns)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Drop rows with more than 50% missing home prices\n",
    "    threshold = len(date_columns) * 0.4\n",
    "    # print(threshold)\n",
    "    \n",
    "    df_cleaned = df[df[\"missing_home_values\"] <= threshold]\n",
    "    # print(df_cleaned)\n",
    "    \n",
    "    df = df_cleaned[filtered_columns]\n",
    "    # print(df.sample(100))\n",
    "    \n",
    "    df = df.apply(lambda row: row.interpolate(method=\"linear\").fillna(method=\"bfill\").fillna(method=\"ffill\"), axis=1)    \n",
    "    print(df)\n",
    "    \n",
    "    # df = df.dropna(subset=date_columns)\n",
    "    # print(df.sample(100))\n",
    "    \n",
    "    # missing_data_columns = df.isnull().sum()\n",
    "    # print(missing_data_columns)\n",
    "    \n",
    "    # Create a column that lists the missing columns per row\n",
    "\n",
    "    # print(df)\n",
    "    \n",
    "    # Drop columns \n",
    "    \n",
    "    # test_missing_data(df)\n",
    "        \n",
    "    # # Heatmap of missing values\n",
    "    # # Calculate the percentage of missing values\n",
    "    # missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "    # print(missing_percentage)\n",
    "    \n",
    "    # # Sort by missing percentage and select top 20\n",
    "    # top_missing = missing_percentage.sort_values(ascending=False).head(20)\n",
    "\n",
    "    # # Plot the top 20\n",
    "    # top_missing.plot(kind='bar', figsize=(10, 5), title=\"Top 20 Columns with Missing Data\")\n",
    "    # plt.xticks(rotation=45)  # Rotate for better visibility\n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, warnings\n",
    "import sklearn.cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Ensure all columns are displayed\n",
    "pd.set_option('display.width', 1000)       # Set a large enough width\n",
    "\n",
    "# Set the column width to avoid truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "'''\n",
    "\n",
    "API reference: https://www.zillow.com/research/data/\n",
    "Data located in data/csv folder\n",
    "Data file path mapped to HOME_VALUES dictionary\n",
    "\n",
    "'''\n",
    "\n",
    "CITY_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 2-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_2_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 3-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_3_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 4-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_4_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 5-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_5_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "def test_missing_data(df):\n",
    "    # Group columns by year\n",
    "    missing_by_year = (\n",
    "        df[[col for col in df.columns if '-' in col]]  # Select only date columns\n",
    "        .isnull()\n",
    "        .mean()\n",
    "        .groupby(lambda col: col[:4])  # Group by year (first 4 characters of column name)\n",
    "        .mean()\n",
    "        * 100\n",
    "    )\n",
    "    \n",
    "    print(missing_by_year)\n",
    "    missing_by_year.plot(kind='line', figsize=(10, 6), marker='o', title=\"Missing Data Percentage by Year\")\n",
    "    plt.ylabel(\"Percentage of Missing Data\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def pd_export_csv(df, filepath=\"df_output.csv\"):\n",
    "    print(\"Loading data frame to csv file \")\n",
    "    try:\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(\"Data frame successfully loaded to csv file:\")\n",
    "        print(filepath)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Error loading data frame to csv\")\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "CONFIG = {\n",
    "    \"start_year\": \"2020\",\n",
    "    \"number_bedrooms\": CITY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"],\n",
    "    \"missing_data_threshold_percent\": 0.05\n",
    "}\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Extract date columns give start_year\n",
    "    date_columns = [col for col in df.columns if col.startswith(\"20\") and col >= CONFIG[\"start_year\"]]\n",
    "    \n",
    "    # Extract missing home values rows (Cities) from data columns\n",
    "    df[\"missing_home_values\"] = df[date_columns].isnull().sum(axis=1)\n",
    "    \n",
    "    # Sort missing home values ascending\n",
    "    df_sorted = df.sort_values(by=\"missing_home_values\", ascending=False)\n",
    "    \n",
    "    # Summarize missing home values by RegionName (city)\n",
    "    missing_summary = df_sorted[['RegionName', 'missing_home_values']]\n",
    "    \n",
    "    # Filter only necessary columns\n",
    "    # filtered_columns = [\"RegionID\", \"SizeRank\", \"RegionName\", \"RegionType\", \"StateName\", \"State\", \"Metro\", \"CountyName\"] + data_columns\n",
    "    filtered_columns = [\"RegionName\", \"State\"] + date_columns\n",
    "\n",
    "    # Drop rows with more than 50% missing home prices\n",
    "    threshold = len(date_columns) * CONFIG[\"missing_data_threshold_percent\"]\n",
    "    \n",
    "    # Extract rows given threshold\n",
    "    df_cleaned = df[df[\"missing_home_values\"] <= threshold]\n",
    "    \n",
    "    # Clean up data frame   \n",
    "    df = df_cleaned[filtered_columns]\n",
    "    \n",
    "    # Fill remaining missing values using interpolation first, then back fill, then front fill\n",
    "    df = df.apply(lambda row: row.interpolate(method=\"linear\").fillna(method=\"bfill\").fillna(method=\"ffill\"), axis=1)  \n",
    "    \n",
    "    start_year_index = 2  # Replace with the index of your desired start year column\n",
    "    start_year_column = df.iloc[:, start_year_index]  # Select the column at index 5\n",
    "    end_year_column = df.iloc[:, -1]  # Select the last column in the DataFrame\n",
    "    \n",
    "    df[\"GrowthRate\"] = (end_year_column - start_year_column) / start_year_column\n",
    "    df[\"Volatility\"] = df[date_columns].std(axis=1)\n",
    "    df[\"AveragePrice\"] = df[date_columns].mean(axis=1)\n",
    "    \n",
    "    columns = [\"GrowthRate\", \"RegionName\", \"State\", \"Volatility\", \"AveragePrice\"] + date_columns\n",
    "    # print(df.sort_values(by=\"AveragePrice\", ascending=False).head(50)[columns])\n",
    "    # df = df.sort_values(by=\"AveragePrice\", ascending=False)[columns]\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "def scale_features(features):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "    \n",
    "def build_k_means_model(scaled_features):\n",
    "    k_means = sklearn.cluster.KMeans(n_clusters=4)\n",
    "    max_sil = 0\n",
    "    k_value = 0\n",
    "    \n",
    "    for idx, k in enumerate(range(2, 11, 1)):\n",
    "        k_means = sklearn.cluster.KMeans(n_clusters=k)\n",
    "        k_means = k_means.fit(scaled_features)\n",
    "        sil = sklearn.metrics.silhouette_score(scaled_features, k_means.labels_)\n",
    "        print(f\"{idx} sil score: {sil}\")\n",
    "        if sil > max_sil:\n",
    "            max_sil = sil\n",
    "            k_value = k\n",
    "    print(f\"\\nBest silhouette score: {max_sil}\")\n",
    "    print(f\"K-Mean value: {k_value}\")\n",
    "    \n",
    "    k_means = sklearn.cluster.KMeans(n_clusters=k_value, random_state=0)\n",
    "    k_means = k_means.fit(scaled_features)\n",
    "    \n",
    "    return {\n",
    "        \"cluster_centers\": k_means.cluster_centers_,\n",
    "        \"labels\": k_means.labels_,\n",
    "        \"k_means\": k_means\n",
    "    }\n",
    "\n",
    "def plot_data(df, feature_one, feature_two, k_means_results):\n",
    "    # Create color mapping\n",
    "    color_map = {0: 'red', 1: 'blue', 2: 'green', 3: 'purple', 4: 'orange'}\n",
    "    colors = [color_map[label] for label in k_means_results[\"labels\"]]\n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    scatter = plt.scatter(df[feature_one], df[feature_two], c=colors, s=10)\n",
    "    # plt.tight_layout()\n",
    "    \n",
    "    # for index, row in df.iterrows():\n",
    "    #     plt.annotate(f\"{row[\"RegionName\"]}, {row[\"State\"]}\",\n",
    "    #                  (row[\"GrowthRate\"], row[\"Volatility\"]),\n",
    "    #                  xytext=(5, 5), textcoords=\"offset points\",\n",
    "    #                  fontsize=8)\n",
    "    # Customize plot\n",
    "    plt.title(\"City Housing Markets Clustered by Growth Rate and Volatility\")\n",
    "    plt.xlabel(\"Growth Rate\")\n",
    "    plt.ylabel(\"Volatility\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.show()\n",
    "    return scatter\n",
    "    \n",
    "\n",
    "def main():        \n",
    "    df = pd.read_csv(CITY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"])\n",
    "    \n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    features = df[[\"GrowthRate\", \"Volatility\", \"AveragePrice\"]]\n",
    "    # print(features)\n",
    "    \n",
    "    scaled_features = scale_features(features)\n",
    "    # print(scaled_features)\n",
    "    \n",
    "    k_means_results = build_k_means_model(scaled_features)\n",
    "    \n",
    "    \n",
    "    scatter = plot_data(df, feature_one=\"GrowthRate\", feature_two=\"Volatility\", k_means_results=k_means_results)\n",
    "    \n",
    "    \n",
    "    # # Create color mapping\n",
    "    # color_map = {0: 'red', 1: 'blue', 2: 'green', 3: 'purple', 4: 'orange'}\n",
    "    # colors = [color_map[label] for label in k_means_results[\"labels\"]]\n",
    "    \n",
    "    # # Create the scatter plot\n",
    "    # plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # scatter = plt.scatter(df, feature_one=\"GrowthRate\", feature_two=\"Volatility\", c=colors, s=10)\n",
    "    # # plt.tight_layout()\n",
    "    \n",
    "    # # for index, row in df.iterrows():\n",
    "    # #     plt.annotate(f\"{row[\"RegionName\"]}, {row[\"State\"]}\",\n",
    "    # #                  (row[\"GrowthRate\"], row[\"Volatility\"]),\n",
    "    # #                  xytext=(5, 5), textcoords=\"offset points\",\n",
    "    # #                  fontsize=8)\n",
    "    \n",
    "\n",
    "    # # Customize plot\n",
    "    # plt.title(\"City Housing Markets Clustered by Growth Rate and Volatility\")\n",
    "    # plt.xlabel(\"Growth Rate\")\n",
    "    # plt.ylabel(\"Volatility\")\n",
    "    # plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, warnings\n",
    "import sklearn.cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Ensure all columns are displayed\n",
    "pd.set_option('display.width', 1000)       # Set a large enough width\n",
    "\n",
    "# Set the column width to avoid truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "'''\n",
    "\n",
    "API reference: https://www.zillow.com/research/data/\n",
    "Data located in data/csv folder\n",
    "Data file path mapped to HOME_VALUES dictionary\n",
    "\n",
    "'''\n",
    "\n",
    "CITY_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 2-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_2_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 3-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_3_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 4-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_4_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 5-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_5_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "def test_missing_data(df):\n",
    "    # Group columns by year\n",
    "    missing_by_year = (\n",
    "        df[[col for col in df.columns if '-' in col]]  # Select only date columns\n",
    "        .isnull()\n",
    "        .mean()\n",
    "        .groupby(lambda col: col[:4])  # Group by year (first 4 characters of column name)\n",
    "        .mean()\n",
    "        * 100\n",
    "    )\n",
    "    \n",
    "    print(missing_by_year)\n",
    "    missing_by_year.plot(kind='line', figsize=(10, 6), marker='o', title=\"Missing Data Percentage by Year\")\n",
    "    plt.ylabel(\"Percentage of Missing Data\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def pd_export_csv(df, filepath=\"df_output.csv\"):\n",
    "    print(\"Loading data frame to csv file \")\n",
    "    try:\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(\"Data frame successfully loaded to csv file:\")\n",
    "        print(filepath)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Error loading data frame to csv\")\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "CONFIG = {\n",
    "    \"start_year\": \"2020\",\n",
    "    \"number_bedrooms\": CITY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"],\n",
    "    \"missing_data_threshold_percent\": 0.05\n",
    "}\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Extract date columns give start_year\n",
    "    date_columns = [col for col in df.columns if col.startswith(\"20\") and col >= CONFIG[\"start_year\"]]\n",
    "    \n",
    "    # Extract missing home values rows (Cities) from data columns\n",
    "    df[\"missing_home_values\"] = df[date_columns].isnull().sum(axis=1)\n",
    "    \n",
    "    # Sort missing home values ascending\n",
    "    df_sorted = df.sort_values(by=\"missing_home_values\", ascending=False)\n",
    "    \n",
    "    # Summarize missing home values by RegionName (city)\n",
    "    missing_summary = df_sorted[['RegionName', 'missing_home_values']]\n",
    "    \n",
    "    # Filter only necessary columns\n",
    "    # filtered_columns = [\"RegionID\", \"SizeRank\", \"RegionName\", \"RegionType\", \"StateName\", \"State\", \"Metro\", \"CountyName\"] + data_columns\n",
    "    filtered_columns = [\"RegionName\", \"State\"] + date_columns\n",
    "\n",
    "    # Drop rows with more than 50% missing home prices\n",
    "    threshold = len(date_columns) * CONFIG[\"missing_data_threshold_percent\"]\n",
    "    \n",
    "    # Extract rows given threshold\n",
    "    df_cleaned = df[df[\"missing_home_values\"] <= threshold]\n",
    "    \n",
    "    # Clean up data frame   \n",
    "    df = df_cleaned[filtered_columns]\n",
    "    \n",
    "    # Fill remaining missing values using interpolation first, then back fill, then front fill\n",
    "    df = df.apply(lambda row: row.interpolate(method=\"linear\").fillna(method=\"bfill\").fillna(method=\"ffill\"), axis=1)  \n",
    "    \n",
    "    start_year_index = 2  # Replace with the index of your desired start year column\n",
    "    start_year_column = df.iloc[:, start_year_index]  # Select the column at index 5\n",
    "    end_year_column = df.iloc[:, -1]  # Select the last column in the DataFrame\n",
    "    \n",
    "    df[\"GrowthRate\"] = (end_year_column - start_year_column) / start_year_column\n",
    "    df[\"Volatility\"] = df[date_columns].std(axis=1)\n",
    "    df[\"AveragePrice\"] = df[date_columns].mean(axis=1)\n",
    "    \n",
    "    columns = [\"GrowthRate\", \"RegionName\", \"State\", \"Volatility\", \"AveragePrice\"] + date_columns\n",
    "    # print(df.sort_values(by=\"AveragePrice\", ascending=False).head(50)[columns])\n",
    "    # df = df.sort_values(by=\"AveragePrice\", ascending=False)[columns]\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "def scale_features(features):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "    \n",
    "def build_k_means_model(scaled_features):\n",
    "    k_means = sklearn.cluster.KMeans(n_clusters=4)\n",
    "    max_sil = 0\n",
    "    k_value = 0\n",
    "    \n",
    "    for idx, k in enumerate(range(2, 11, 1)):\n",
    "        k_means = sklearn.cluster.KMeans(n_clusters=k)\n",
    "        k_means = k_means.fit(scaled_features)\n",
    "        sil = sklearn.metrics.silhouette_score(scaled_features, k_means.labels_)\n",
    "        if sil > max_sil:\n",
    "            max_sil = sil\n",
    "            k_value = k\n",
    "    print(f\"\\nBest silhouette score: {max_sil}\")\n",
    "    print(f\"K-Mean value: {k_value}\")\n",
    "    \n",
    "    k_means = sklearn.cluster.KMeans(n_clusters=k_value, random_state=0)\n",
    "    k_means = k_means.fit(scaled_features)\n",
    "    \n",
    "    return {\n",
    "        \"cluster_centers\": k_means.cluster_centers_,\n",
    "        \"labels\": k_means.labels_,\n",
    "        \"k_means\": k_means\n",
    "    }\n",
    "\n",
    "def plot_data(df, feature_one, feature_two, k_means_results, num_bedrooms, city_names=False):\n",
    "    # Create color mapping\n",
    "    color_map = {0: 'red', 1: 'blue', 2: 'green', 3: 'purple', 4: 'orange'}\n",
    "    colors = [color_map[label] for label in k_means_results[\"labels\"]]\n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.scatter(df[feature_one], df[feature_two], c=colors, s=10)\n",
    "    if city_names:\n",
    "        for index, row in df.iterrows():\n",
    "            plt.annotate(f\"{row[\"RegionName\"]}, {row[\"State\"]}\",\n",
    "                        (row[feature_one], row[feature_two]),\n",
    "                        xytext=(5, 5), textcoords=\"offset points\",\n",
    "                        fontsize=8)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f\"{num_bedrooms}\\nCity Housing Markets Clustered by {feature_one} and {feature_two}\")\n",
    "    plt.xlabel(feature_one)\n",
    "    plt.ylabel(feature_two)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def prompt_user():\n",
    "    # Valid inputs for features and bedrooms\n",
    "    valid_inputs = [\"GrowthRate\", \"Volatility\", \"AveragePrice\"]\n",
    "    valid_bedrooms = {\n",
    "        \"1\": \"1-Bedroom\",\n",
    "        \"2\": \"2-Bedroom\",\n",
    "        \"3\": \"3-Bedroom\",\n",
    "        \"4\": \"4-Bedroom\",\n",
    "        \"5\": \"5+ Bedroom\"\n",
    "    }\n",
    "    \n",
    "    def display_bedroom_options():\n",
    "        print(\"\\nSelect number of bedrooms:\")\n",
    "        for num, desc in valid_bedrooms.items():\n",
    "            print(f\"{num}. {desc}\")\n",
    "        print(\"(Enter 'e' to exit)\")\n",
    "    \n",
    "    def display_feature_options():\n",
    "        print(\"\\nAvailable variables to visualize:\")\n",
    "        for i, option in enumerate(valid_inputs, 1):\n",
    "            print(f\"{i}. {option}\")\n",
    "        print(\"(Enter 'e' to exit)\")\n",
    "\n",
    "    def get_bedroom_choice():\n",
    "        while True:\n",
    "            display_bedroom_options()\n",
    "            choice = input(\"\\nEnter number of bedrooms: \").strip()\n",
    "            \n",
    "            if choice.lower() == 'e':\n",
    "                return None\n",
    "                \n",
    "            if choice in valid_bedrooms:\n",
    "                return choice\n",
    "                \n",
    "            print(\"\\nInvalid input. Please enter a number between 1-5.\")\n",
    "\n",
    "    def get_feature(prompt_text):\n",
    "        while True:\n",
    "            display_feature_options()\n",
    "            choice = input(prompt_text).strip()\n",
    "            \n",
    "            # Check for exit\n",
    "            if choice.lower() == 'e':\n",
    "                return None\n",
    "            \n",
    "            # Handle numeric input\n",
    "            if choice.isdigit() and 1 <= int(choice) <= len(valid_inputs):\n",
    "                return valid_inputs[int(choice) - 1]\n",
    "            \n",
    "            # Handle text input\n",
    "            if choice in valid_inputs:\n",
    "                return choice\n",
    "            \n",
    "            print(f\"\\nInvalid input. Please enter a number (1-{len(valid_inputs)})\" \n",
    "                  f\" or the exact variable name.\")\n",
    "\n",
    "    # Get bedroom choice first\n",
    "    bedrooms = get_bedroom_choice()\n",
    "    if bedrooms is None:\n",
    "        return None\n",
    "\n",
    "    # Get first feature\n",
    "    feature_one = get_feature(\"\\nSelect first variable: \")\n",
    "    if feature_one is None:\n",
    "        return None\n",
    "\n",
    "    # Get second feature\n",
    "    feature_two = get_feature(\"\\nSelect second variable: \")\n",
    "    if feature_two is None:\n",
    "        return None\n",
    "        \n",
    "    # Check if same features selected\n",
    "    if feature_one == feature_two:\n",
    "        print(\"\\nWarning: You've selected the same variable twice. \"\n",
    "              \"This may not provide meaningful insights.\")\n",
    "        if input(\"Continue anyway? (y/n): \").lower() != 'y':\n",
    "            return prompt_user()  # Restart selection\n",
    "\n",
    "    match bedrooms:\n",
    "        case \"1\":\n",
    "            bedrooms = \"ZHVI 1-Bedroom Time Series ($)\"\n",
    "        case \"2\":\n",
    "            bedrooms = \"ZHVI 2-Bedroom Time Series ($)\"\n",
    "        case \"3\":\n",
    "            bedrooms = \"ZHVI 3-Bedroom Time Series ($)\"\n",
    "        case \"4\":\n",
    "            bedrooms = \"ZHVI 4-Bedroom Time Series ($)\"\n",
    "        case \"5\":\n",
    "            bedrooms = \"ZHVI 5-Bedroom Time Series ($)\"\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"bedrooms\": bedrooms,\n",
    "        \"features\": [feature_one, feature_two]\n",
    "    }\n",
    "\n",
    "def main():        \n",
    "    user_input = prompt_user()\n",
    "        \n",
    "    df = pd.read_csv(CITY_HOME_VALUES[user_input[\"bedrooms\"]])\n",
    "    \n",
    "    df = preprocess_data(df)\n",
    "    \n",
    "    features = df[[\"GrowthRate\", \"Volatility\", \"AveragePrice\"]]\n",
    "    \n",
    "    scaled_features = scale_features(features)\n",
    "    \n",
    "    k_means_results = build_k_means_model(scaled_features)\n",
    "    \n",
    "    plot_data(df=df, \n",
    "              feature_one=user_input[\"features\"][0], \n",
    "              feature_two=user_input[\"features\"][1], \n",
    "              k_means_results=k_means_results, \n",
    "              city_names=False,\n",
    "              num_bedrooms=user_input[\"bedrooms\"])    \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib\n",
    "Cluster data visualization using matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sklearn.cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Ensure all columns are displayed\n",
    "pd.set_option('display.width', 1000)       # Set a large enough width\n",
    "\n",
    "# Set the column width to avoid truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "'''\n",
    "API reference: https://www.zillow.com/research/data/\n",
    "Data located in data/csv folder\n",
    "Data file path mapped to CITY_HOME_VALUES dictionary\n",
    "\n",
    "Housing Market Cluster Analysis program: Visualizes and analyzes housing market patterns \n",
    "across cities using Zillow's Home Value Index (ZHVI) data, allowing users to explore \n",
    "relationships between growth rates, volatility, and average prices for different \n",
    "bedroom configurations.\n",
    "'''\n",
    "\n",
    "# Configure data file paths\n",
    "CITY_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 2-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_2_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 3-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_3_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 4-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_4_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 5-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_5_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "CONFIG = {\n",
    "    \"start_year\": \"2020\",\n",
    "    \"number_bedrooms\": CITY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"],\n",
    "    \"missing_data_threshold_percent\": 0.25\n",
    "}\n",
    "\n",
    "# Test for missing data\n",
    "def test_missing_data(df):\n",
    "    # Group columns by year\n",
    "    missing_by_year = (\n",
    "        df[[col for col in df.columns if '-' in col]]  # Select only date columns\n",
    "        .isnull()\n",
    "        .mean()\n",
    "        .groupby(lambda col: col[:4])  # Group by year (first 4 characters of column name)\n",
    "        .mean()\n",
    "        * 100\n",
    "    )\n",
    "    \n",
    "    print(missing_by_year)\n",
    "    missing_by_year.plot(kind='line', figsize=(10, 6), marker='o', title=\"Missing Data Percentage by Year\")\n",
    "    plt.ylabel(\"Percentage of Missing Data\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def pd_export_csv(df, filepath=\"housing_df_output.csv\"):\n",
    "    print(\"Loading data frame to csv file \")\n",
    "    try:\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(\"Data frame successfully loaded to csv file:\")\n",
    "        print(filepath)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Error loading data frame to csv\")\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses the data frame by extracting date columns, filtering out rows with missing home values, \n",
    "    and filling in missing values using interpolation, back fill, and front fill.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The data frame to preprocess\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed data frame\n",
    "    \"\"\"\n",
    "    # Extract date columns give start_year\n",
    "    date_columns = [col for col in df.columns if col.startswith(\"20\") and col >= CONFIG[\"start_year\"]]\n",
    "    \n",
    "    # Extract missing home values rows (Cities) from data columns\n",
    "    df[\"missing_home_values\"] = df[date_columns].isnull().sum(axis=1)\n",
    "    \n",
    "    # Sort missing home values ascending\n",
    "    df_sorted = df.sort_values(by=\"missing_home_values\", ascending=False)\n",
    "    \n",
    "    # Summarize missing home values by RegionName (city)\n",
    "    missing_summary = df_sorted[['RegionName', 'missing_home_values']]\n",
    "    \n",
    "    # Filter only necessary columns\n",
    "    # filtered_columns = [\"RegionID\", \"SizeRank\", \"RegionName\", \"RegionType\", \"StateName\", \"State\", \"Metro\", \"CountyName\"] + data_columns\n",
    "    filtered_columns = [\"RegionName\", \"State\"] + date_columns\n",
    "\n",
    "    # Drop rows with more than 50% missing home prices\n",
    "    threshold = len(date_columns) * CONFIG[\"missing_data_threshold_percent\"]\n",
    "    \n",
    "    # Extract rows given threshold\n",
    "    df_cleaned = df[df[\"missing_home_values\"] <= threshold]\n",
    "    \n",
    "    # Clean up data frame   \n",
    "    df = df_cleaned[filtered_columns]\n",
    "    \n",
    "    # Fill remaining missing values using interpolation first, then back fill, then front fill\n",
    "    df = df.apply(lambda row: row.interpolate(method=\"linear\").fillna(method=\"bfill\").fillna(method=\"ffill\"), axis=1)  \n",
    "    \n",
    "    start_year_index = 2  # Index of the first date column\n",
    "    start_year_column = df.iloc[:, start_year_index]  # Select the first column in the DataFrame\n",
    "    end_year_column = df.iloc[:, -1]  # Select the last column in the DataFrame\n",
    "    \n",
    "    # Calculate growth rate, volatility, and average price\n",
    "    df[\"GrowthRate\"] = (end_year_column - start_year_column) / start_year_column\n",
    "    df[\"Volatility\"] = df[date_columns].std(axis=1)\n",
    "    df[\"AveragePrice\"] = df[date_columns].mean(axis=1)\n",
    "    \n",
    "    columns = [\"GrowthRate\", \"RegionName\", \"State\", \"Volatility\", \"AveragePrice\"] + date_columns\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "def scale_features(features):\n",
    "    \"\"\"\n",
    "    Standardizes numerical features by removing the mean and scaling to unit variance.\n",
    "    Args:\n",
    "        features (pd.DataFrame): DataFrame containing numerical features to be scaled\n",
    "    Returns:\n",
    "        numpy.ndarray: Scaled feature array with mean=0 and variance=1\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "    \n",
    "def build_k_means_model(scaled_features):\n",
    "    \"\"\"\n",
    "    Builds a K-Means clustering model using the given scaled features and returns the cluster centers, labels, and model.\n",
    "    Uses silhouette scoring to determine the optimal number of clusters (k) between 2 and 10.\n",
    "\n",
    "    Args:\n",
    "        scaled_features (numpy.ndarray): Standardized numerical features to be used for clustering\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'cluster_centers': numpy.ndarray\n",
    "                Coordinates of cluster centers,\n",
    "            'labels': numpy.ndarray\n",
    "                Cluster labels for each data point,\n",
    "            'k_means': sklearn.cluster.KMeans\n",
    "                Fitted K-Means model with optimal number of clusters\n",
    "        }\n",
    "    \"\"\"    \n",
    "    max_sil = 0\n",
    "    k_value = 0\n",
    "    \n",
    "    # Determine optimal number of clusters using silhouette score\n",
    "    for k in range(2, 11, 1):\n",
    "        k_means = sklearn.cluster.KMeans(n_clusters=k)\n",
    "        k_means = k_means.fit(scaled_features)\n",
    "        sil = sklearn.metrics.silhouette_score(scaled_features, k_means.labels_)\n",
    "        if sil > max_sil:\n",
    "            max_sil = sil\n",
    "            k_value = k\n",
    "            \n",
    "    print(f\"\\nBest silhouette score: {max_sil}\")\n",
    "    print(f\"K-Mean value: {k_value}\")\n",
    "    \n",
    "    k_means = sklearn.cluster.KMeans(n_clusters=k_value, random_state=0)\n",
    "    k_means = k_means.fit(scaled_features)\n",
    "    \n",
    "    return {\n",
    "        \"cluster_centers\": k_means.cluster_centers_,\n",
    "        \"labels\": k_means.labels_,\n",
    "        \"k_means\": k_means\n",
    "    }\n",
    "\n",
    "def plot_data(df, feature_one, feature_two, k_means_results, num_bedrooms, city_names=False):\n",
    "    \"\"\"\n",
    "    Creates a scatter plot visualizing housing market clusters based on two selected features.\n",
    "    Points are color-coded by cluster and can optionally display city names.\n",
    "    Args:\n",
    "       df (pd.DataFrame): Housing market data\n",
    "       feature_one (str): Column name for x-axis feature \n",
    "       feature_two (str): Column name for y-axis feature\n",
    "       k_means_results (dict): Dictionary with clustering results including 'labels'\n",
    "       num_bedrooms (str): Bedroom count identifier for plot title\n",
    "       city_names (bool, optional): Show city name labels. Defaults to False\n",
    "\n",
    "    Returns:\n",
    "       None: Displays matplotlib scatter plot\n",
    "    \"\"\"\n",
    "    # Create color mapping\n",
    "    color_map = {0: 'red', 1: 'blue', 2: 'green', 3: 'purple', 4: 'orange'}\n",
    "    colors = [color_map[label] for label in k_means_results[\"labels\"]]\n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.scatter(df[feature_one], df[feature_two], c=colors, s=10)\n",
    "    if city_names:\n",
    "        for index, row in df.iterrows():\n",
    "            plt.annotate(f\"{row[\"RegionName\"]}, {row[\"State\"]}\",\n",
    "                        (row[feature_one], row[feature_two]),\n",
    "                        xytext=(5, 5), textcoords=\"offset points\",\n",
    "                        fontsize=6)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f\"{num_bedrooms}\\nCity Housing Markets Clustered by {feature_one} and {feature_two}\")\n",
    "    plt.xlabel(feature_one)\n",
    "    plt.ylabel(feature_two)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def prompt_user():\n",
    "    \"\"\"\n",
    "    Prompts user to select bedroom count and visualization features.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'bedrooms': str\n",
    "                ZHVI dataset identifier based on bedroom count,\n",
    "            'features': list[str]\n",
    "                Two feature names for visualization\n",
    "        } or None if user exits\n",
    "    \"\"\"\n",
    "    # Valid inputs for features and bedrooms\n",
    "    valid_inputs = [\"GrowthRate\", \"Volatility\", \"AveragePrice\"]\n",
    "    valid_bedrooms = {\n",
    "        \"1\": \"1-Bedroom\",\n",
    "        \"2\": \"2-Bedroom\",\n",
    "        \"3\": \"3-Bedroom\",\n",
    "        \"4\": \"4-Bedroom\",\n",
    "        \"5\": \"5+ Bedroom\"\n",
    "    }\n",
    "    \n",
    "    def display_bedroom_options():\n",
    "        print(\"\\nSelect number of bedrooms:\")\n",
    "        for num, desc in valid_bedrooms.items():\n",
    "            print(f\"{num}. {desc}\")\n",
    "        print(\"(Enter 'e' to exit)\")\n",
    "    \n",
    "    def display_feature_options():\n",
    "        print(\"\\nAvailable variables to visualize:\")\n",
    "        for i, option in enumerate(valid_inputs, 1):\n",
    "            print(f\"{i}. {option}\")\n",
    "        print(\"(Enter 'e' to exit)\")\n",
    "\n",
    "    def get_bedroom_choice():\n",
    "        while True:\n",
    "            display_bedroom_options()\n",
    "            choice = input(\"\\nEnter number of bedrooms: \").strip()\n",
    "            \n",
    "            if choice.lower() == 'e':\n",
    "                return None\n",
    "                \n",
    "            if choice in valid_bedrooms:\n",
    "                return choice\n",
    "                \n",
    "            print(\"\\nInvalid input. Please enter a number between 1-5.\")\n",
    "\n",
    "    def get_feature(prompt_text):\n",
    "        while True:\n",
    "            display_feature_options()\n",
    "            choice = input(prompt_text).strip()\n",
    "            \n",
    "            # Check for exit\n",
    "            if choice.lower() == 'e':\n",
    "                return None\n",
    "            \n",
    "            # Handle numeric input\n",
    "            if choice.isdigit() and 1 <= int(choice) <= len(valid_inputs):\n",
    "                return valid_inputs[int(choice) - 1]\n",
    "            \n",
    "            # Handle text input\n",
    "            if choice in valid_inputs:\n",
    "                return choice\n",
    "            \n",
    "            print(f\"\\nInvalid input. Please enter a number (1-{len(valid_inputs)})\" \n",
    "                  f\" or the exact variable name.\")\n",
    "\n",
    "    # Get bedroom choice first\n",
    "    bedrooms = get_bedroom_choice()\n",
    "    if bedrooms is None:\n",
    "        return None\n",
    "\n",
    "    # Get first feature\n",
    "    feature_one = get_feature(\"\\nSelect first variable: \")\n",
    "    if feature_one is None:\n",
    "        return None\n",
    "\n",
    "    # Get second feature\n",
    "    feature_two = get_feature(\"\\nSelect second variable: \")\n",
    "    if feature_two is None:\n",
    "        return None\n",
    "        \n",
    "    # Check if same features selected\n",
    "    if feature_one == feature_two:\n",
    "        print(\"\\nWarning: You've selected the same variable twice. \"\n",
    "              \"This may not provide meaningful insights.\")\n",
    "        if input(\"Continue anyway? (y/n): \").lower() != 'y':\n",
    "            return prompt_user()  # Restart selection\n",
    "\n",
    "    match bedrooms:\n",
    "        case \"1\":\n",
    "            bedrooms = \"ZHVI 1-Bedroom Time Series ($)\"\n",
    "        case \"2\":\n",
    "            bedrooms = \"ZHVI 2-Bedroom Time Series ($)\"\n",
    "        case \"3\":\n",
    "            bedrooms = \"ZHVI 3-Bedroom Time Series ($)\"\n",
    "        case \"4\":\n",
    "            bedrooms = \"ZHVI 4-Bedroom Time Series ($)\"\n",
    "        case \"5\":\n",
    "            bedrooms = \"ZHVI 5-Bedroom Time Series ($)\"\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"bedrooms\": bedrooms,\n",
    "        \"features\": [feature_one, feature_two]\n",
    "    }\n",
    "\n",
    "def main():        \n",
    "    user_input = prompt_user()\n",
    "    \n",
    "    if user_input:\n",
    "        try:\n",
    "            df = pd.read_csv(CITY_HOME_VALUES[user_input[\"bedrooms\"]])\n",
    "            \n",
    "            df = preprocess_data(df)\n",
    "            \n",
    "            features = df[[\"GrowthRate\", \"Volatility\", \"AveragePrice\"]]\n",
    "            \n",
    "            scaled_features = scale_features(features)\n",
    "            \n",
    "            k_means_results = build_k_means_model(scaled_features)\n",
    "            \n",
    "            plot_data(df=df, \n",
    "                    feature_one=user_input[\"features\"][0], \n",
    "                    feature_two=user_input[\"features\"][1], \n",
    "                    k_means_results=k_means_results, \n",
    "                    city_names=True,\n",
    "                    num_bedrooms=user_input[\"bedrooms\"])   \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\") \n",
    "    else:\n",
    "        print(\"No user input provided. Exiting program.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotly\n",
    "Cluster data visualization using plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sklearn.cluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Ensure all columns are displayed\n",
    "pd.set_option('display.width', 1000)       # Set a large enough width\n",
    "\n",
    "# Set the column width to avoid truncation\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "'''\n",
    "API reference: https://www.zillow.com/research/data/\n",
    "Data located in data/csv folder\n",
    "Data file path mapped to CITY_HOME_VALUES dictionary\n",
    "\n",
    "Housing Market Cluster Analysis program: Visualizes and analyzes housing market patterns \n",
    "across cities using Zillow's Home Value Index (ZHVI) data, allowing users to explore \n",
    "relationships between growth rates, volatility, and average prices for different \n",
    "bedroom configurations.\n",
    "'''\n",
    "\n",
    "# Configure data file paths\n",
    "CITY_HOME_VALUES = {\n",
    "    'ZHVI 1-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_1_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 2-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_2_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 3-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_3_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 4-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_4_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "    'ZHVI 5-Bedroom Time Series ($)': './data/csv/city/City_zhvi_bdrmcnt_5_uc_sfrcondo_tier_0.33_0.67_sm_sa_month.csv',\n",
    "}\n",
    "\n",
    "CONFIG = {\n",
    "    \"start_year\": \"2020\",\n",
    "    \"number_bedrooms\": CITY_HOME_VALUES[\"ZHVI 1-Bedroom Time Series ($)\"],\n",
    "    \"missing_data_threshold_percent\": 0.25\n",
    "}\n",
    "\n",
    "# Test for missing data\n",
    "def test_missing_data(df):\n",
    "    # Group columns by year\n",
    "    missing_by_year = (\n",
    "        df[[col for col in df.columns if '-' in col]]  # Select only date columns\n",
    "        .isnull()\n",
    "        .mean()\n",
    "        .groupby(lambda col: col[:4])  # Group by year (first 4 characters of column name)\n",
    "        .mean()\n",
    "        * 100\n",
    "    )\n",
    "    \n",
    "    print(missing_by_year)\n",
    "    missing_by_year.plot(kind='line', figsize=(10, 6), marker='o', title=\"Missing Data Percentage by Year\")\n",
    "    plt.ylabel(\"Percentage of Missing Data\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def pd_export_csv(df, filepath=\"housing_df_output.csv\"):\n",
    "    print(\"Loading data frame to csv file \")\n",
    "    try:\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(\"Data frame successfully loaded to csv file:\")\n",
    "        print(filepath)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Error loading data frame to csv\")\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "def preprocess_data(df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses the data frame by extracting date columns, filtering out rows with missing home values, \n",
    "    and filling in missing values using interpolation, back fill, and front fill.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The data frame to preprocess\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed data frame\n",
    "    \"\"\"\n",
    "    # Extract date columns give start_year\n",
    "    date_columns = [col for col in df.columns if col.startswith(\"20\") and col >= CONFIG[\"start_year\"]]\n",
    "    \n",
    "    # Extract missing home values rows (Cities) from data columns\n",
    "    df[\"missing_home_values\"] = df[date_columns].isnull().sum(axis=1)\n",
    "    \n",
    "    # Sort missing home values ascending\n",
    "    df_sorted = df.sort_values(by=\"missing_home_values\", ascending=False)\n",
    "    \n",
    "    # Summarize missing home values by RegionName (city)\n",
    "    missing_summary = df_sorted[['RegionName', 'missing_home_values']]\n",
    "    \n",
    "    # Filter only necessary columns\n",
    "    # filtered_columns = [\"RegionID\", \"SizeRank\", \"RegionName\", \"RegionType\", \"StateName\", \"State\", \"Metro\", \"CountyName\"] + data_columns\n",
    "    filtered_columns = [\"RegionName\", \"State\"] + date_columns\n",
    "\n",
    "    # Drop rows with more than 50% missing home prices\n",
    "    threshold = len(date_columns) * CONFIG[\"missing_data_threshold_percent\"]\n",
    "    \n",
    "    # Extract rows given threshold\n",
    "    df_cleaned = df[df[\"missing_home_values\"] <= threshold]\n",
    "    \n",
    "    # Clean up data frame   \n",
    "    df = df_cleaned[filtered_columns]\n",
    "    \n",
    "    # Fill remaining missing values using interpolation first, then back fill, then front fill\n",
    "    df = df.apply(lambda row: row.interpolate(method=\"linear\").fillna(method=\"bfill\").fillna(method=\"ffill\"), axis=1)  \n",
    "    \n",
    "    start_year_index = 2  # Index of the first date column\n",
    "    start_year_column = df.iloc[:, start_year_index]  # Select the first column in the DataFrame\n",
    "    end_year_column = df.iloc[:, -1]  # Select the last column in the DataFrame\n",
    "    \n",
    "    # Calculate growth rate, volatility, and average price\n",
    "    df[\"GrowthRate\"] = (end_year_column - start_year_column) / start_year_column\n",
    "    df[\"Volatility\"] = df[date_columns].std(axis=1)\n",
    "    df[\"AveragePrice\"] = df[date_columns].mean(axis=1)\n",
    "    \n",
    "    columns = [\"GrowthRate\", \"RegionName\", \"State\", \"Volatility\", \"AveragePrice\"] + date_columns\n",
    "    df = df[columns]\n",
    "    return df\n",
    "\n",
    "def scale_features(features):\n",
    "    \"\"\"\n",
    "    Standardizes numerical features by removing the mean and scaling to unit variance.\n",
    "    Args:\n",
    "        features (pd.DataFrame): DataFrame containing numerical features to be scaled\n",
    "    Returns:\n",
    "        numpy.ndarray: Scaled feature array with mean=0 and variance=1\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(features)\n",
    "    \n",
    "def build_k_means_model(scaled_features):\n",
    "    \"\"\"\n",
    "    Builds a K-Means clustering model using the given scaled features and returns the cluster centers, labels, and model.\n",
    "    Uses silhouette scoring to determine the optimal number of clusters (k) between 2 and 10.\n",
    "\n",
    "    Args:\n",
    "        scaled_features (numpy.ndarray): Standardized numerical features to be used for clustering\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'cluster_centers': numpy.ndarray\n",
    "                Coordinates of cluster centers,\n",
    "            'labels': numpy.ndarray\n",
    "                Cluster labels for each data point,\n",
    "            'k_means': sklearn.cluster.KMeans\n",
    "                Fitted K-Means model with optimal number of clusters\n",
    "        }\n",
    "    \"\"\"    \n",
    "    max_sil = 0\n",
    "    k_value = 0\n",
    "    \n",
    "    # Determine optimal number of clusters using silhouette score\n",
    "    for k in range(2, 11, 1):\n",
    "        k_means = sklearn.cluster.KMeans(n_clusters=k)\n",
    "        k_means = k_means.fit(scaled_features)\n",
    "        sil = sklearn.metrics.silhouette_score(scaled_features, k_means.labels_)\n",
    "        if sil > max_sil:\n",
    "            max_sil = sil\n",
    "            k_value = k\n",
    "            \n",
    "    print(f\"\\nBest silhouette score: {max_sil}\")\n",
    "    print(f\"K-Mean value: {k_value}\")\n",
    "    \n",
    "    k_means = sklearn.cluster.KMeans(n_clusters=k_value, random_state=0)\n",
    "    k_means = k_means.fit(scaled_features)\n",
    "    \n",
    "    return {\n",
    "        \"cluster_centers\": k_means.cluster_centers_,\n",
    "        \"labels\": k_means.labels_,\n",
    "        \"k_means\": k_means\n",
    "    }\n",
    "\n",
    "def plot_data(df, feature_one, feature_two, k_means_results, num_bedrooms, city_names=False):\n",
    "    \"\"\"\n",
    "    Creates a scatter plot visualizing housing market clusters based on two selected features.\n",
    "    Points are color-coded by cluster and can optionally display city names.\n",
    "    Args:\n",
    "       df (pd.DataFrame): Housing market data\n",
    "       feature_one (str): Column name for x-axis feature \n",
    "       feature_two (str): Column name for y-axis feature\n",
    "       k_means_results (dict): Dictionary with clustering results including 'labels'\n",
    "       num_bedrooms (str): Bedroom count identifier for plot title\n",
    "       city_names (bool, optional): Show city name labels. Defaults to False\n",
    "\n",
    "    Returns:\n",
    "       None: Displays matplotlib scatter plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add cluster labels to the DataFrame\n",
    "    df[\"Cluster\"] = k_means_results[\"labels\"].astype(str)\n",
    "    \n",
    "    # Add city names to the DataFrame if not already present\n",
    "    df[\"CityNames\"] = df[\"RegionName\"] + \", \" + df[\"State\"]\n",
    "    \n",
    "    ## Create color mapping\n",
    "    color_map = {\n",
    "        0: 'red', \n",
    "        1: 'blue', \n",
    "        2: 'green', \n",
    "        3: 'purple', \n",
    "        4: 'orange'\n",
    "    }\n",
    "        \n",
    "    fig = px.scatter(\n",
    "        df, \n",
    "        x=feature_one, \n",
    "        y=feature_two, \n",
    "        color=\"Cluster\", \n",
    "        title=f\"{num_bedrooms}\\nCity Housing Markets Clustered by {feature_one} and {feature_two}\",\n",
    "        hover_data={\"Cluster\": False, \"CityNames\": True},\n",
    "        color_discrete_map=color_map\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "def prompt_user():\n",
    "    \"\"\"\n",
    "    Prompts user to select bedroom count and visualization features.\n",
    "\n",
    "    Returns:\n",
    "        dict: {\n",
    "            'bedrooms': str\n",
    "                ZHVI dataset identifier based on bedroom count,\n",
    "            'features': list[str]\n",
    "                Two feature names for visualization\n",
    "        } or None if user exits\n",
    "    \"\"\"\n",
    "    # Valid inputs for features and bedrooms\n",
    "    valid_inputs = [\"GrowthRate\", \"Volatility\", \"AveragePrice\"]\n",
    "    valid_bedrooms = {\n",
    "        \"1\": \"1-Bedroom\",\n",
    "        \"2\": \"2-Bedroom\",\n",
    "        \"3\": \"3-Bedroom\",\n",
    "        \"4\": \"4-Bedroom\",\n",
    "        \"5\": \"5+ Bedroom\"\n",
    "    }\n",
    "    \n",
    "    def display_bedroom_options():\n",
    "        print(\"\\nSelect number of bedrooms:\")\n",
    "        for num, desc in valid_bedrooms.items():\n",
    "            print(f\"{num}. {desc}\")\n",
    "        print(\"(Enter 'e' to exit)\")\n",
    "    \n",
    "    def display_feature_options():\n",
    "        print(\"\\nAvailable variables to visualize:\")\n",
    "        for i, option in enumerate(valid_inputs, 1):\n",
    "            print(f\"{i}. {option}\")\n",
    "        print(\"(Enter 'e' to exit)\")\n",
    "\n",
    "    def get_bedroom_choice():\n",
    "        while True:\n",
    "            display_bedroom_options()\n",
    "            choice = input(\"\\nEnter number of bedrooms: \").strip()\n",
    "            \n",
    "            if choice.lower() == 'e':\n",
    "                return None\n",
    "                \n",
    "            if choice in valid_bedrooms:\n",
    "                return choice\n",
    "                \n",
    "            print(\"\\nInvalid input. Please enter a number between 1-5.\")\n",
    "\n",
    "    def get_feature(prompt_text):\n",
    "        while True:\n",
    "            display_feature_options()\n",
    "            choice = input(prompt_text).strip()\n",
    "            \n",
    "            # Check for exit\n",
    "            if choice.lower() == 'e':\n",
    "                return None\n",
    "            \n",
    "            # Handle numeric input\n",
    "            if choice.isdigit() and 1 <= int(choice) <= len(valid_inputs):\n",
    "                return valid_inputs[int(choice) - 1]\n",
    "            \n",
    "            # Handle text input\n",
    "            if choice in valid_inputs:\n",
    "                return choice\n",
    "            \n",
    "            print(f\"\\nInvalid input. Please enter a number (1-{len(valid_inputs)})\" \n",
    "                  f\" or the exact variable name.\")\n",
    "\n",
    "    # Get bedroom choice first\n",
    "    bedrooms = get_bedroom_choice()\n",
    "    if bedrooms is None:\n",
    "        return None\n",
    "\n",
    "    # Get first feature\n",
    "    feature_one = get_feature(\"\\nSelect first variable: \")\n",
    "    if feature_one is None:\n",
    "        return None\n",
    "\n",
    "    # Get second feature\n",
    "    feature_two = get_feature(\"\\nSelect second variable: \")\n",
    "    if feature_two is None:\n",
    "        return None\n",
    "        \n",
    "    # Check if same features selected\n",
    "    if feature_one == feature_two:\n",
    "        print(\"\\nWarning: You've selected the same variable twice. \"\n",
    "              \"This may not provide meaningful insights.\")\n",
    "        if input(\"Continue anyway? (y/n): \").lower() != 'y':\n",
    "            return prompt_user()  # Restart selection\n",
    "\n",
    "    match bedrooms:\n",
    "        case \"1\":\n",
    "            bedrooms = \"ZHVI 1-Bedroom Time Series ($)\"\n",
    "        case \"2\":\n",
    "            bedrooms = \"ZHVI 2-Bedroom Time Series ($)\"\n",
    "        case \"3\":\n",
    "            bedrooms = \"ZHVI 3-Bedroom Time Series ($)\"\n",
    "        case \"4\":\n",
    "            bedrooms = \"ZHVI 4-Bedroom Time Series ($)\"\n",
    "        case \"5\":\n",
    "            bedrooms = \"ZHVI 5-Bedroom Time Series ($)\"\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"bedrooms\": bedrooms,\n",
    "        \"features\": [feature_one, feature_two]\n",
    "    }\n",
    "\n",
    "def main():        \n",
    "    user_input = prompt_user()\n",
    "    \n",
    "    if user_input:\n",
    "        try:\n",
    "            df = pd.read_csv(CITY_HOME_VALUES[user_input[\"bedrooms\"]])\n",
    "            \n",
    "            df = preprocess_data(df)\n",
    "            \n",
    "            features = df[[\"GrowthRate\", \"Volatility\", \"AveragePrice\"]]\n",
    "            \n",
    "            scaled_features = scale_features(features)\n",
    "            \n",
    "            k_means_results = build_k_means_model(scaled_features)\n",
    "            \n",
    "            plot_data(df=df, \n",
    "                    feature_one=user_input[\"features\"][0], \n",
    "                    feature_two=user_input[\"features\"][1], \n",
    "                    k_means_results=k_means_results, \n",
    "                    city_names=True,\n",
    "                    num_bedrooms=user_input[\"bedrooms\"])   \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\") \n",
    "    else:\n",
    "        print(\"No user input provided. Exiting program.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
